---
# Global configuration of computing nodes.
images:
  default: vggp-v60-j322-692e75a7c101-main
  gpu: vgcn~rockylinux-9-latest-x86_64~+generic+workers-gpu+internal~20240318~65722~dev~220eac2~with_latest_drivers
  secure: vggp-v60-secure-j322-692e75a7c101-main
  htcondor-secondary: vgcn~workers+internal~rockylinux-8.6-x86_64~2023-10-26~43739~htcondor-secondary~ebb20b8~kysrpex_local_build
  htcondor-secondary-gpu: vgcn~workers-gpu+internal~rockylinux-8.6-x86_64~2023-11-16~34096~htcondor-secondary~a23fbb0~kysrpex_local_build
  rocky-9: vgcn~rockylinux-9-latest-x86_64~+generic+workers+internal~20240314~40429~dev~9f80854~2nd_test_no_kernel_lt_by_mira
network: bioinf
secgroups:
  - ufr-ingress
  # interactive-egress: A reduced more stringent egress rule for all nodes
  - interactive-egress
sshkey: cloud3
pubkeys:
  # The public key(s) that will be accepted when SSHing to a machine.
  - "AAAAB3NzaC1yc2EAAAABIwAAAQEAuSG1VOumQhbJfOyalJjS4lPC8eeeL02ld/VI2BFApyMfwbB1QxehY3lMBXt/cBTzqU3MxgJQVzNr/AgjHa5rKn2hSGMfKAdaX2tG686k715bBjRm9rJNhmc8KSH9tVS35M0HwRXMfiGvSmb5qJ6utWRZe6RM2JMIbqqI5Oc4tbzPPVKk1+yvT1JdYuyqAOp2yvQbOqKaXmqOhPdPNaJZMI4o+UHmmb8FH6OTDY27G7X7u07ZPwVi1j+6ZFVMQZqg1RhUdg9kmHpHwMX7P6NcD4G9GsISHIh92eva9xgWYGiS0wUsmOWTNgAzzsfRZjMFep+jB2wup6QN7XpMw97eTw=="

# Behavior of `synchronize.py''
graceful: false

nodes_inventory:
  c1.c28m225d50: 7
  c1.c28m475d50: 19
  c1.c36m100d50: 32
  c1.c36m225d50: 11
  c1.c36m900d50: 1
  c1.c36m975d50: 8
  c1.c60m1975d50: 1
  c1.c120m225d50: 12
  c1.c120m425d50: 22
  c1.c125m425d50: 16
  c1.c28m935d50: 4
  c1.c28m875d50: 2
  g1.c14m40g1d50: 4
  g1.c8m40g1d50: 4

deployment:
  # worker-c120m225-htcondor-secondary:
  #   count: 1 #12
  #   flavor: c1.c120m225d50
  #   group: compute
  #   docker: true
  #   image: htcondor-secondary
  #   secondary_htcondor_cluster: true
  #   volume:
  #     size: 1024
  #     type: default
  #   cgroups:
  #     mem_limit_policy: hard
  #     mem_reserved_size: 2048

  worker-fetch-htcondor-secondary:
    count: 0
    flavor: c1.c36m100d50
    group: upload
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-interactive-htcondor-secondary:
    count: 4 #8
    flavor: c1.c36m100d50
    group: interactive
    docker: true
    image: htcondor-secondary
    secondary_htcondor_cluster: true
    volume:
      size: 1024
      type: default
  worker-c28m475-htcondor-secondary:
    count: 10 #19
    flavor: c1.c28m475d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c28m225-htcondor-secondary:
    count: 0
    flavor: c1.c28m225d50
    group: compute_test
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c36m100-htcondor-secondary:
    count: 26 #32
    flavor: c1.c36m100d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c36m225-htcondor-secondary:
    count: 11 #11
    flavor: c1.c36m225d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c36m900-htcondor-secondary:
    count: 1 #1 it's a c1.c36m975d50 host with probably a faulty memory bank
    flavor: c1.c36m900d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c36m975-htcondor-secondary:
    count: 8 #8
    flavor: c1.c36m975d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c28m935-htcondor-secondary:
    count: 4 #4
    flavor: c1.c28m935d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c28m875-htcondor-secondary:
    count: 2 #2
    flavor: c1.c28m875d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c64m2-htcondor-secondary:
    count: 1 #1
    flavor: c1.c60m1975d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c120m225-htcondor-secondary:
    count: 12 #12
    flavor: c1.c120m225d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c120m425-htcondor-secondary:
    count: 22
    flavor: c1.c120m425d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c125m425-htcondor-secondary:
    count: 16 #16
    flavor: c1.c125m425d50
    group: compute
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: hard
      mem_reserved_size: 2048
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  worker-c14m40g1-htcondor-secondary:
    count: 4 #4
    flavor: g1.c14m40g1d50
    group: compute_gpu
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 1024
    image: gpu
    secondary_htcondor_cluster: true
  worker-c8m40g1-htcondor-secondary:
    count: 4 #4
    flavor: g1.c8m40g1d50
    group: compute_gpu
    docker: true
    volume:
      size: 1024
      type: default
    cgroups:
      mem_limit_policy: soft
      mem_reserved_size: 1024
    image: htcondor-secondary-gpu
    secondary_htcondor_cluster: true

  # Trainings
  # These will overlap April 8-17
  training-kmb6:
    count: 1
    flavor: c1.c28m225d50
    start: 2024-03-01
    end: 2024-05-17
    group: training-kmb615
    image: htcondor-secondary
    secondary_htcondor_cluster: true
  training-woco:
    count: 1
    flavor: c1.c28m225d50
    start: 2024-04-08
    end: 2024-05-10
    group: training-woco2024
  training-e502:
    count: 1
    flavor: c1.c28m225d50
    start: 2024-04-09
    end: 2024-04-09
    group: training-e5020-2024-04-09
  training-joca:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-04-12
    end: 2024-04-12
    group: training-joca-epigenomics-24
    image: htcondor-secondary
    secondary_htcondor_cluster: true

  training-geno:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-05-07
    end: 2024-05-10
    group: training-genome-assembly-2024
    image: htcondor-secondary
    secondary_htcondor_cluster: true

  training-nort:
    count: 2
    flavor: c1.c28m225d50
    start: 2024-06-07
    end: 2024-06-07
    group: training-northumbria-7jun24
    image: htcondor-secondary
    secondary_htcondor_cluster: true
